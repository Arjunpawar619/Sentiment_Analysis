{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/regression-part2-automated-ml.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and prepare data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import math\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1679874224379
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin by creating a dataframe to hold the taxi data. Then preview the data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\r\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\r\n",
        "from azureml.core import Workspace, Dataset\r\n",
        "\r\n",
        "subscription_id = 'd61b5034-941c-4a0f-9918-5dcfe01f46fd'\r\n",
        "resource_group = 'rg-arjun-ai'\r\n",
        "workspace_name = 'ML-arjun'\r\n",
        "\r\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "dataset = Dataset.get_by_name(workspace, name='twitter_asset')\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "      cl1         cl2                           cl3       cl4  \\\n0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n...   ...         ...                           ...       ...   \n1995    0  1468280681  Tue Apr 07 00:43:16 PDT 2009  NO_QUERY   \n1996    0  1468280970  Tue Apr 07 00:43:22 PDT 2009  NO_QUERY   \n1997    0  1468281170  Tue Apr 07 00:43:26 PDT 2009  NO_QUERY   \n1998    0  1468281205  Tue Apr 07 00:43:29 PDT 2009  NO_QUERY   \n1999    0  1468281484  Tue Apr 07 00:43:33 PDT 2009  NO_QUERY   \n\n                  cl5                                                cl6  \n0     _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n1       scotthamilton  is upset that he can't update his Facebook by ...  \n2            mattycus  @Kenichan I dived many times for the ball. Man...  \n3             ElleCTF    my whole body feels itchy and like its on fire   \n4              Karoli  @nationwideclass no, it's not behaving at all....  \n...               ...                                                ...  \n1995           chomma                          @roxy_yeah yep a loser.    \n1996          EvilSue  and finito! All bathroom contractors been thru...  \n1997        lexikitty  @caitlinaudrey awww!  that sucks! are you goin...  \n1998         terrajen  Sorry, SF. Rescheduling my SF trip for this co...  \n1999          MonBon_  2morw  I get my blasted wisdom teeth pulled! N...  \n\n[2000 rows x 6 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cl1</th>\n      <th>cl2</th>\n      <th>cl3</th>\n      <th>cl4</th>\n      <th>cl5</th>\n      <th>cl6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>0</td>\n      <td>1468280681</td>\n      <td>Tue Apr 07 00:43:16 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>chomma</td>\n      <td>@roxy_yeah yep a loser.</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>0</td>\n      <td>1468280970</td>\n      <td>Tue Apr 07 00:43:22 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>EvilSue</td>\n      <td>and finito! All bathroom contractors been thru...</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>0</td>\n      <td>1468281170</td>\n      <td>Tue Apr 07 00:43:26 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>lexikitty</td>\n      <td>@caitlinaudrey awww!  that sucks! are you goin...</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>0</td>\n      <td>1468281205</td>\n      <td>Tue Apr 07 00:43:29 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>terrajen</td>\n      <td>Sorry, SF. Rescheduling my SF trip for this co...</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>0</td>\n      <td>1468281484</td>\n      <td>Tue Apr 07 00:43:33 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>MonBon_</td>\n      <td>2morw  I get my blasted wisdom teeth pulled! N...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 6 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874227675
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['cl1','cl2','cl3','cl4','cl5'], axis=1, inplace=True)\r\n",
        "\r\n",
        "df.rename(columns={'cl6':'Tweets'},inplace=True)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874233271
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = df.copy()\r\n",
        "sample_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "                                                 Tweets\n0     @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1     is upset that he can't update his Facebook by ...\n2     @Kenichan I dived many times for the ball. Man...\n3       my whole body feels itchy and like its on fire \n4     @nationwideclass no, it's not behaving at all....\n...                                                 ...\n1995                          @roxy_yeah yep a loser.  \n1996  and finito! All bathroom contractors been thru...\n1997  @caitlinaudrey awww!  that sucks! are you goin...\n1998  Sorry, SF. Rescheduling my SF trip for this co...\n1999  2morw  I get my blasted wisdom teeth pulled! N...\n\n[2000 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>@roxy_yeah yep a loser.</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>and finito! All bathroom contractors been thru...</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>@caitlinaudrey awww!  that sucks! are you goin...</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>Sorry, SF. Rescheduling my SF trip for this co...</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>2morw  I get my blasted wisdom teeth pulled! N...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874236047
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "(2000, 1)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874239237
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contractions_dict = {\"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\", \"doesn't\":\"does not\",\"who'll\":\"who will\", \"you'll\":\"you will\"}\r\n",
        "# Regular expression for finding contractions\r\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\r\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\r\n",
        "    def replace(match):\r\n",
        "        return contractions_dict[match.group(0)]\r\n",
        "    return contractions_re.sub(replace, text)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874241084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stopwords\r\n",
        "stop_words = set(stopwords.words('english'))\r\n",
        "stop_words.add('http')\r\n",
        "def remove_stopwords(text):\r\n",
        "    return \" \".join([word for word in str(text).split() if word not in stop_words])"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874242770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\r\n",
        "def lemmatize_words(text):\r\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874244197
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data['Tweets'] = sample_data['Tweets'].apply(lambda x: re.sub(r\"\\S*https?:\\S*\", \"\", x)) # remove https links\r\n",
        "\r\n",
        "sample_data['Tweets'] = sample_data['Tweets'].apply(lambda x: re.sub( r'(^|[^@\\w])@(\\w{1,15})\\b', '', x )) # remove usernames\r\n",
        "\r\n",
        "sample_data['Tweets']= sample_data['Tweets'].apply(lambda x:expand_contractions(x)) # replace contractions\r\n",
        "\r\n",
        "sample_data['Tweets']= sample_data['Tweets'].str.lower() # make text lower case\r\n",
        "\r\n",
        "sample_data['Tweets']= sample_data['Tweets'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x)) #remove punctuations\r\n",
        "\r\n",
        "sample_data['Tweets']= sample_data['Tweets'].apply(lambda x: re.sub('W*dw*','',x)) \r\n",
        "\r\n",
        "sample_data['Tweets']= sample_data['Tweets'].apply(lambda x: remove_stopwords(x)) # remove stopwords\r\n",
        "\r\n",
        "sample_data['Tweets']= sample_data['Tweets'].apply(lambda text: lemmatize_words(text)) # lemmatize words"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874257220
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874259822
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data['sentiment_scores'] = sample_data['Tweets'].apply(lambda text: sia.polarity_scores(text))\r\n",
        "sample_data['compound_score'] = sample_data['sentiment_scores'].apply(lambda score_dict: score_dict['compound'])\r\n",
        "sample_data['sentiment'] = sample_data['compound_score'].apply(lambda score: 'Positive' if score > 0 else (\"Negative\" if score < 0 else \"Neutral\"))"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874261066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top ten postive tweets and top negative tweets\r\n",
        "#sample_data['testing']= sample_data['compound_score'].apply(lambda x: \"Positive\" if x>0.9 else (\"Negative\" if x < -0.85 else \"Neutral\"))"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874273300
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data.rename(columns={\"Tweets\": \"Reformed_Tweets\"}, inplace=True)\r\n",
        "sample_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "                                        Reformed_Tweets  \\\n0               awww bummer shoula got avi carr thir ay   \n1     upset cant upate facebook texting might cry re...   \n2       ive many time ball manage save 50 rest go bouns   \n3                        whole boy feel itchy like fire   \n4                                  behaving im cant see   \n...                                                 ...   \n1995                                          yep loser   \n1996  finito bathroom contractor thru house quote in...   \n1997                          awww suck going syney one   \n1998  sorry sf rescheuling sf trip coming weeken mi ...   \n1999  2morw get blaste wisom teeth pulle nee sleepcn...   \n\n                                       sentiment_scores  compound_score  \\\n0     {'neg': 0.271, 'neu': 0.729, 'pos': 0.0, 'comp...         -0.3818   \n1     {'neg': 0.441, 'neu': 0.559, 'pos': 0.0, 'comp...         -0.7269   \n2     {'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...          0.4939   \n3     {'neg': 0.45, 'neu': 0.3, 'pos': 0.25, 'compou...         -0.2500   \n4     {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000   \n...                                                 ...             ...   \n1995  {'neg': 0.607, 'neu': 0.0, 'pos': 0.393, 'comp...         -0.2960   \n1996  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000   \n1997  {'neg': 0.42, 'neu': 0.58, 'pos': 0.0, 'compou...         -0.4404   \n1998  {'neg': 0.115, 'neu': 0.885, 'pos': 0.0, 'comp...         -0.0772   \n1999  {'neg': 0.371, 'neu': 0.629, 'pos': 0.0, 'comp...         -0.7096   \n\n     sentiment  \n0     Negative  \n1     Negative  \n2     Positive  \n3     Negative  \n4      Neutral  \n...        ...  \n1995  Negative  \n1996   Neutral  \n1997  Negative  \n1998  Negative  \n1999  Negative  \n\n[2000 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Reformed_Tweets</th>\n      <th>sentiment_scores</th>\n      <th>compound_score</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>awww bummer shoula got avi carr thir ay</td>\n      <td>{'neg': 0.271, 'neu': 0.729, 'pos': 0.0, 'comp...</td>\n      <td>-0.3818</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>upset cant upate facebook texting might cry re...</td>\n      <td>{'neg': 0.441, 'neu': 0.559, 'pos': 0.0, 'comp...</td>\n      <td>-0.7269</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ive many time ball manage save 50 rest go bouns</td>\n      <td>{'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...</td>\n      <td>0.4939</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>whole boy feel itchy like fire</td>\n      <td>{'neg': 0.45, 'neu': 0.3, 'pos': 0.25, 'compou...</td>\n      <td>-0.2500</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>behaving im cant see</td>\n      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>yep loser</td>\n      <td>{'neg': 0.607, 'neu': 0.0, 'pos': 0.393, 'comp...</td>\n      <td>-0.2960</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>finito bathroom contractor thru house quote in...</td>\n      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>awww suck going syney one</td>\n      <td>{'neg': 0.42, 'neu': 0.58, 'pos': 0.0, 'compou...</td>\n      <td>-0.4404</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>sorry sf rescheuling sf trip coming weeken mi ...</td>\n      <td>{'neg': 0.115, 'neu': 0.885, 'pos': 0.0, 'comp...</td>\n      <td>-0.0772</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>2morw get blaste wisom teeth pulle nee sleepcn...</td>\n      <td>{'neg': 0.371, 'neu': 0.629, 'pos': 0.0, 'comp...</td>\n      <td>-0.7096</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874274944
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transform = pd.concat([df,sample_data], axis=1)\r\n",
        "df_transform"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "                                                 Tweets  \\\n0     @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n1     is upset that he can't update his Facebook by ...   \n2     @Kenichan I dived many times for the ball. Man...   \n3       my whole body feels itchy and like its on fire    \n4     @nationwideclass no, it's not behaving at all....   \n...                                                 ...   \n1995                          @roxy_yeah yep a loser.     \n1996  and finito! All bathroom contractors been thru...   \n1997  @caitlinaudrey awww!  that sucks! are you goin...   \n1998  Sorry, SF. Rescheduling my SF trip for this co...   \n1999  2morw  I get my blasted wisdom teeth pulled! N...   \n\n                                        Reformed_Tweets  \\\n0               awww bummer shoula got avi carr thir ay   \n1     upset cant upate facebook texting might cry re...   \n2       ive many time ball manage save 50 rest go bouns   \n3                        whole boy feel itchy like fire   \n4                                  behaving im cant see   \n...                                                 ...   \n1995                                          yep loser   \n1996  finito bathroom contractor thru house quote in...   \n1997                          awww suck going syney one   \n1998  sorry sf rescheuling sf trip coming weeken mi ...   \n1999  2morw get blaste wisom teeth pulle nee sleepcn...   \n\n                                       sentiment_scores  compound_score  \\\n0     {'neg': 0.271, 'neu': 0.729, 'pos': 0.0, 'comp...         -0.3818   \n1     {'neg': 0.441, 'neu': 0.559, 'pos': 0.0, 'comp...         -0.7269   \n2     {'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...          0.4939   \n3     {'neg': 0.45, 'neu': 0.3, 'pos': 0.25, 'compou...         -0.2500   \n4     {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000   \n...                                                 ...             ...   \n1995  {'neg': 0.607, 'neu': 0.0, 'pos': 0.393, 'comp...         -0.2960   \n1996  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000   \n1997  {'neg': 0.42, 'neu': 0.58, 'pos': 0.0, 'compou...         -0.4404   \n1998  {'neg': 0.115, 'neu': 0.885, 'pos': 0.0, 'comp...         -0.0772   \n1999  {'neg': 0.371, 'neu': 0.629, 'pos': 0.0, 'comp...         -0.7096   \n\n     sentiment  \n0     Negative  \n1     Negative  \n2     Positive  \n3     Negative  \n4      Neutral  \n...        ...  \n1995  Negative  \n1996   Neutral  \n1997  Negative  \n1998  Negative  \n1999  Negative  \n\n[2000 rows x 5 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Reformed_Tweets</th>\n      <th>sentiment_scores</th>\n      <th>compound_score</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n      <td>awww bummer shoula got avi carr thir ay</td>\n      <td>{'neg': 0.271, 'neu': 0.729, 'pos': 0.0, 'comp...</td>\n      <td>-0.3818</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>upset cant upate facebook texting might cry re...</td>\n      <td>{'neg': 0.441, 'neu': 0.559, 'pos': 0.0, 'comp...</td>\n      <td>-0.7269</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>ive many time ball manage save 50 rest go bouns</td>\n      <td>{'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...</td>\n      <td>0.4939</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>whole boy feel itchy like fire</td>\n      <td>{'neg': 0.45, 'neu': 0.3, 'pos': 0.25, 'compou...</td>\n      <td>-0.2500</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>behaving im cant see</td>\n      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>@roxy_yeah yep a loser.</td>\n      <td>yep loser</td>\n      <td>{'neg': 0.607, 'neu': 0.0, 'pos': 0.393, 'comp...</td>\n      <td>-0.2960</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>and finito! All bathroom contractors been thru...</td>\n      <td>finito bathroom contractor thru house quote in...</td>\n      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>@caitlinaudrey awww!  that sucks! are you goin...</td>\n      <td>awww suck going syney one</td>\n      <td>{'neg': 0.42, 'neu': 0.58, 'pos': 0.0, 'compou...</td>\n      <td>-0.4404</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>Sorry, SF. Rescheduling my SF trip for this co...</td>\n      <td>sorry sf rescheuling sf trip coming weeken mi ...</td>\n      <td>{'neg': 0.115, 'neu': 0.885, 'pos': 0.0, 'comp...</td>\n      <td>-0.0772</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>2morw  I get my blasted wisdom teeth pulled! N...</td>\n      <td>2morw get blaste wisom teeth pulle nee sleepcn...</td>\n      <td>{'neg': 0.371, 'neu': 0.629, 'pos': 0.0, 'comp...</td>\n      <td>-0.7096</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 5 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874286379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_transform.to_csv(\"output.csv\", sep=\",\", index=False)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679874312608
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "jeffshep"
      }
    ],
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "network_required": false,
    "kernel_info": {
      "name": "python38-azureml"
    },
    "msauthor": "trbye",
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "categories": [
      "SDK v1",
      "tutorials"
    ],
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}